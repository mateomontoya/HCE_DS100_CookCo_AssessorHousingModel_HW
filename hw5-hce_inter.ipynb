{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Predicting Housing Prices\n",
    "\n",
    "## Due Date: 6:00pm Tuesday, March 19\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this homework, we will go through the iterative process of specifying, fitting, and analyzing the performance of a  model.  \n",
    "\n",
    "In the first portion of the assignment, we will guide you through some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Next, you will add a new feature to the dataset, before specifying and fitting a linear model to a few features of the housing data to predict housing prices. Finally, we will analyze the error of the model and brainstorm ways to improve the model's performance.\n",
    "\n",
    "After this homework, you should feel comfortable with the following:\n",
    "\n",
    "1. Simple feature engineering\n",
    "1. Using sklearn to build linear models\n",
    "1. Building a data pipeline using pandas\n",
    "\n",
    "Next week's homework will continue working with this dataset to address more advanced and subtle issues with modeling.\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "[Question 1](#q1) | 3\n",
    "[Question 2](#q2) | 2\n",
    "[Question 3](#q3) | 1\n",
    "[Question 4](#q4) | 1\n",
    "[Question 5](#q5) | 2\n",
    "[Question 6](#q6) | 2\n",
    "[Question 7a](#q7a) | 1\n",
    "[Question 7b](#q7b) | 2\n",
    "[Question 8a](#q8a) | 1\n",
    "[Question 8b](#q8b) | 1\n",
    "[Question 8c](#q8c) | 2\n",
    "[Question 8d](#q8d) | 2\n",
    "Total | 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "The [Chicago housing dataset](https://datacatalog.cookcountyil.gov/Property-Taxation/Cook-County-Assessor-s-Assessment-Data/bcnq-qi2z) consists of over 350,000 records taken from Cook County's Assessor’s Office in Illinois describing houses sold in Cook County (Chicago and the surrounding area) in 2018.  The data set has 86(!) features in total.  An explanation of each variable can be found in the included `codebook.txt` file.  The information was used in computing assessed values for individual residential properties sold in Cook County, Illinois in 2018. This was done by the sitting Cook County Assesor, Kaegi, and their office.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a County Assessor? A Living History\n",
    "\n",
    "A county assessor is the person responsible for collecting estimates of parcels of land within a county, about every 3 years. The assessments of properties come from estimating what the property would be priced at or how much it would cost to construct the parcel, deducting depreciation. Assessments are done in order to determine the property taxes owed by the property owner. The Cook County Assessor, Fritz Kaegi, has promised to make assessments more transparent. This is a departure from the past Cook County Assessor, who has historically produced [“racially discriminatory assessments and taxes.\"](https://harris.uchicago.edu/news-events/news/prof-chris-berry-testifies-institutional-racism-cook-county-property-taxes)\n",
    "\n",
    "In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios.  The lawsuit includes claims that the county assessor’s office undervalued homes in parts of Cook County where more white residents lived.  At the same time, Berrios’ office overvalued homes in areas with less white residents by census data.  [This forced non-white residents to pay more in property taxes](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html), [while white residents pay less](https://www.clccrul.org/bpnc-v-berrios-facts?rq=berrios).\n",
    "\n",
    "Currently, the lawsuit is still underway and there was a third plaintiff added in February 2019.\n",
    "This problem is systemic and historic as well, with property assessments for tax purposes placing an unequal and unfair tax burden on African American and Hispanic residents.  The county assessors role in our data is to come up with the parcels’ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cook County Open Data Initiative. A break from the past\n",
    "\n",
    "The Cook County Open Data Initiative is an effort being conducted by numerous government  agencies in Cook County, opening data to the public on such diverse topics as “Emergency Management”, “Health”, “Courts and Legal”, and “Pets and Animals”. The Cook County Assessor’s Office (CCAO) is part of this initiative, and has published the data which generated their office’s model on how they value a house.\n",
    "\n",
    "In essence, this data is the exact data that was used to generate the active model deployed by the CCAO to value houses in Cook County. [Access to their model (in R) can be found here](https://gitlab.com/ccao-data-science---modeling). Given that the data is publically accessible, the Cook County Assessor has solicited community member's input on the quality of the model. This effort includes soliciting comment on how their model may or may not reinforce biases that have been identified by many critics of the Cook County Assessors Office. This is a huge change from the previous practice of the Cook County Assessor's Office, which assigned house values manually with a team of assessors making decisions with little or no possible public oversight.\n",
    "\n",
    "If you are interested in reading more about how this initiative is being presented by the CCAO, [you can read their Medium article](https://medium.com/@AssessorCook/why-the-cook-county-assessors-office-made-its-residential-assessment-code-and-data-public-c964acfa7b0f).\n",
    "\n",
    "You can read more about the context of this data set from the [Cook Cook Assessor's Office Data Narrative](https://datacatalog.cookcountyil.gov/stories/s/Cook-County-Assessor-Valuation-Data-Release/p2kt-hk36)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_county_housing = pd.read_csv('Cook_County_Assessor_s_Modeling_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cook_county_housing.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cook_county_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "np.random.seed(1338)\n",
    "full_data_len = len(cook_county_housing)\n",
    "shuffled_indices = np.random.permutation(full_data_len)\n",
    "\n",
    "# Set train_indices to the first 80% of shuffled_indices and and test_indices to the rest.\n",
    "train_indices = shuffled_indices[:int(full_data_len * 0.8)]\n",
    "test_indices = shuffled_indices[int(full_data_len * 0.8):]\n",
    "\n",
    "# Create train and test` by indexing into `full_data` using \n",
    "# `train_indices` and `test_indices`\n",
    "train_data = cook_county_housing.iloc[train_indices]\n",
    "test_data = cook_county_housing.iloc[test_indices].drop('Sale Price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-529585fba8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 228135 observations and 86 features in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m228135\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m86\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 67034 observations and 85 features in test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m67034\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 'Sale Price' is hidden in the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 228135 observations and 86 features in training data\n",
    "assert train_data.shape == (228135, 86)\n",
    "# 67034 observations and 85 features in test data\n",
    "assert test_data.shape == (67034, 85)\n",
    "# 'Sale Price' is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values\n",
    "# Every other column in the test data should be in the training data\n",
    "assert len(np.intersect1d(test_data.columns.values, \n",
    "                          train_data.columns.values)) == 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating the Training Data into Training and Testing Data\n",
    "\n",
    "We need to separate out the data into training and test sections. This allows us to assess the strength of our model on the test data after we train it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "np.random.seed(1338)\n",
    "train_data_len = len(train_data)\n",
    "shuffled_indices = np.random.permutation(train_data_len)\n",
    "\n",
    "# Set train_indices to the first 80% of shuffled_indices and and test_indices to the rest.\n",
    "train_indices = shuffled_indices[:int(train_data_len * 0.8)]\n",
    "test_indices = shuffled_indices[int(train_data_len * 0.8):]\n",
    "\n",
    "# Create train and test` by indexing into `full_data` using \n",
    "# `train_indices` and `test_indices`\n",
    "training_data = train_data.iloc[train_indices]\n",
    "testing_data = train_data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Contextualizing the Data\n",
    "\n",
    "The next order of business is to contextualize the variables in our data.  The Cook County data set contains information that the CCAO has deemed important to assess home value.  A more detailed description of each variable is available on [their website](https://datacatalog.cookcountyil.gov/Property-Taxation/Cook-County-Assessor-s-Modeling-Data/5pge-nu6u). The list of column values there contains notes on what each value or string represents, and sometimes cautions about the quality of a given variable.  **You should take some time to familiarize yourself with the variables before moving forward.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cook_county_housing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bcdb088fc145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcook_county_housing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cook_county_housing' is not defined"
     ]
    }
   ],
   "source": [
    "cook_county_housing.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0a\n",
    "\n",
    "Take a moment to assess the granularity of this data set. What is contained in a row?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0b\n",
    "\n",
    "Given that this data represents houses, do you think there are enough features and types of features to give an accurate picture of a home’s value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0c\n",
    "\n",
    "Given that this data was used by the Cook County Assessor's Office to generate the model that they employ today, name two columns that have probably been added by the data scientists.\n",
    "\n",
    "*Hint* You can go back to the list of columns from the CCAO's wesbite or you can generate a list of the columns in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Leave your scratch work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*\n",
    "\n",
    "Solution: There are many instances of columns that have been duplicated as a square or log of a previous column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0d\n",
    "\n",
    "Recalling that these columns were collected by the Cook County Assessor's Office to generate house values, find a column that more than likely would only be collected in Cook County. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*\n",
    "\n",
    "Solution: O'Hare noise column would only be relevant to Cook County becase it represents whether or not a house is in flight paths of the Chicago O'Hare Airport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba0f6926b0dafefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Exploratory Data Analysis\n",
    "\n",
    "In this section, we will make a series of exploratory visualizations and interpret them.\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### Sale Price\n",
    "We begin by examining a [raincloud plot](https://micahallen.org/2018/03/15/introducing-raincloud-plots/amp/?__twitter_impression=true) (a combination of a KDE, a histogram, a strip plot, and a box plot) of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15d483a695655cea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.distplot(\n",
    "    training_data['Sale Price'], \n",
    "    ax=axs[0]\n",
    ")\n",
    "sns.stripplot(\n",
    "    training_data['Sale Price'], \n",
    "    jitter=0.4, \n",
    "    size=3,\n",
    "    ax=axs[1],\n",
    "    alpha=0.3\n",
    ")\n",
    "sns.boxplot(\n",
    "    training_data['Sale Price'],\n",
    "    width=0.3, \n",
    "    ax=axs[1],\n",
    "    showfliers=False,\n",
    ")\n",
    "\n",
    "# Align axes\n",
    "spacer = np.max(training_data['Sale Price']) * 0.05\n",
    "xmin = np.min(training_data['Sale Price']) - spacer\n",
    "xmax = np.max(training_data['Sale Price']) + spacer\n",
    "axs[0].set_xlim((xmin, xmax))\n",
    "axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "# Remove some axis text\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_visible(False)\n",
    "axs[1].yaxis.set_visible(False)\n",
    "\n",
    "# Put the two plots together\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "# Adjust boxplot fill to be white\n",
    "axs[1].artists[0].set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45e5037c06db70f0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.145080e+05\n",
       "mean     2.399628e+05\n",
       "std      3.504762e+05\n",
       "min      0.000000e+00\n",
       "25%      5.100000e+04\n",
       "50%      1.700000e+05\n",
       "75%      3.070000e+05\n",
       "max      7.100000e+07\n",
       "Name: Sale Price, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Sale Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Omit Below Cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-592d5f41ebd67ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1  <a name=\"q1\"></a>\n",
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `SalePrice` in the training set is left-skew.\n",
    "1. The mean of `SalePrice` in the training set is greater than the median.\n",
    "1. At least 25% of the houses in the training set sold for more than \\$200,000.00.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to `True` or `False`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-592d5f41ebd67ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1  <a name=\"q1\"></a>\n",
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `SalePrice` in the training set is left-skew.\n",
    "1. The mean of `SalePrice` in the training set is greater than the median.\n",
    "1. At least 25% of the houses in the training set sold for more than \\$200,000.00.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to `True` or `False`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 <a name=\"q3\"></a>\n",
    "\n",
    "We know from the data narrative that this dataset primarily consists of house sales. However, there are still many rows which have sale price numbers which are much below what any reasonable property would sell for. There are 1557 rows with the value 0, and 50 other rows with values at or below 10. Remove these values and the outliers of houses which sold for more than 10 million with the remove_outliers function given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c7ceef4e47b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvariable\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnumerical\u001b[0m \u001b[0moutliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    return data.loc[(data[variable] > lower) & (data[variable] < upper), :]\n",
    "\n",
    "training_data = remove_outliers(training_data, 'Sale Price', upper=10000000, lower=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b79f6c15fd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ok' is not defined"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Feature Engineering\n",
    "\n",
    "In this section we will create a new feature out of existing ones through a simple data transformation.\n",
    "\n",
    "Feature engineering is a critical point in the data science process. We are essentially saying \"These are the features we feel are important to predicting our metric.\" A good data scientist balances statistical reasoning and their own critical thinking.\n",
    "\n",
    "### Bathrooms\n",
    "\n",
    "Let's create a groundbreaking new feature. Due to recent advances in Universal WC Enumeration Theory, we now know that Total Bathrooms can be calculated as:\n",
    "\n",
    "$$ \\text{TotalBathrooms}=(\\text{BsmtFullBath} + \\text{FullBath}) + \\dfrac{1}{2}(\\text{BsmtHalfBath} + \\text{HalfBath})$$\n",
    "\n",
    "The actual proof is beyond the scope of this class, but we will use the result in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 <a name=\"q4\"></a>\n",
    "\n",
    "Write a function `add_total_bathrooms(data)` that returns a copy of `data` with an additional column called `TotalBathrooms` computed by the formula above.  **Treat missing values as zeros**.  Remember that you can make use of vectorized code here; you shouldn't need any `for` statements. \n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-42b4e0afe27e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwith_bathrooms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_total_bathrooms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "def add_total_bathrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least 4 numeric columns \n",
    "            Bsmt_Full_Bath, Full_Bath, Bsmt_Half_Bath, and Half_Bath\n",
    "    \"\"\"\n",
    "    with_bathrooms = data.copy()\n",
    "    bath_vars = ['Full Baths', 'Half Baths']\n",
    "    weights = pd.Series([1, 0.5], index=bath_vars)\n",
    "    ## Solution\n",
    "    with_bathrooms = with_bathrooms.fillna({var: 0 for var in bath_vars})\n",
    "    with_bathrooms['Total Bathrooms'] = with_bathrooms[bath_vars].dot(weights)\n",
    "    return with_bathrooms\n",
    "\n",
    "training_data = add_total_bathrooms(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 <a name=\"q5\"></a>\n",
    "\n",
    "Create a visualization that clearly and succintly shows that `TotalBathrooms` is associated with `SalePrice`. Your visualization should avoid overplotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f509efb4be9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BEGIN SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Total Bathrooms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sale Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sale Price distribution for each value of Total Bathrooms'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# END SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "sns.boxplot(x='Total Bathrooms', y='Sale Price', data=training_data, whis=5);\n",
    "plt.title('Sale Price distribution for each value of Total Bathrooms');\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "We've reached the point where we can specify a model. But first, we will load a fresh copy of the data, just in case our code above produced any undesired side-effects. Run the cell below to store a fresh copy of the data from `ames_train.csv` in a dataframe named `full_data`. We will also store the number of rows in `full_data` in the variable `full_data_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fresh copy of the data and get its length\n",
    "full_data = pd.read_csv('Cook_County_Assessor_s_Modeling_Data.csv')\n",
    "full_data_len = len(full_data)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 <a name=\"q6\"></a>\n",
    "\n",
    "Now, let's split the data set into a training set and test set. We will use the training set to fit our model's parameters, and we will use the test set to estimate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on unseen data.\n",
    "\n",
    "\"Don't we already have a test set in `ames_test.csv`?\" you might wonder. The sale prices for `ames_test.csv` aren't provided, so we're constructing our own test set for which we know the outputs.\n",
    "\n",
    "In the cell below, split the data in `full_data` into two DataFrames named `train` and `test`. Let `train` contain 80% of the data, and let `test` contain the remaining 20% of the data. \n",
    "\n",
    "To do this, first create two NumPy arrays named `train_indices` and `test_indices`. `train_indices` should contain a *random* 80% of the indices in `full_data`, and `test_indices` should contain the remaining 20% of the indices. Then, use these arrays to index into `full_data` to create your final `train` and `test` DataFrames.\n",
    "\n",
    "*The provided tests check that you not only answered correctly, but ended up with the exact same train/test split as our reference implementation. Later testing is easier this way.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "np.random.seed(1337)\n",
    "shuffled_indices = np.random.permutation(full_data_len)\n",
    "\n",
    "# Set train_indices to the first 80% of shuffled_indices and and test_indices to the rest.\n",
    "train_indices = shuffled_indices[:int(full_data_len * 0.8)] # SOLUTION\n",
    "test_indices = shuffled_indices[int(full_data_len * 0.8):] # SOLUTION\n",
    "\n",
    "assert len(train_indices) != len(test_indices)\n",
    "\n",
    "# Create train and test` by indexing into `full_data` using \n",
    "# `train_indices` and `test_indices`\n",
    "train = full_data.iloc[train_indices] # SOLUTION\n",
    "test = full_data.iloc[test_indices] # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ok.grade(\"q6\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acdc861fd11912e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Reusable Pipeline\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, it's best to define functions/methods that can apply the pipeline to any dataset.  We will now encapsulate our entire pipeline into a single function `process_data_gm`.  gm is shorthand for \"guided model\". We select a handful of features to use from the many that are available.\n",
    "\n",
    "Additionally, creating reproducible work is an important part of data science. When you leave a project, readability and transferability of your code is necessary for future work on the project by other data scientists. Therefore, it’s better to use abstract identifiers to navigate code. For example, in this notebook, we refer to columns by their names--that way, if a new dataset comes in with different column indices, we’ll be able to know which columns to target when adapting code. \n",
    "\n",
    "In the CCAO's case, for example, they felt that making their model into a reproducible and easily reusable pipeline was an essential part of their mission as a public office. In this case, this allows citizens and other entities with sufficient technical skills to understand and even critique their work openly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2fe1d82b2c19d1fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def process_data_gm(data):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    \n",
    "    data = remove_outliers(data, 'Sale Price', upper=10000000, lower=0)\n",
    "    data = add_total_bathrooms(data)\n",
    "    \n",
    "    \n",
    "    data = data.dropna(subset=['Sale Price', 'Building Square Feet', \n",
    "                                 'Full Baths', 'Half Baths',\n",
    "                                 'Bedrooms', 'Land Square Feet',\n",
    "                                 'Rooms', 'Fireplaces'])\n",
    "    \n",
    "    \n",
    "    # Transform Data, Select Features\n",
    "    data = select_columns(data, \n",
    "                          'Sale Price', \n",
    "                          'Land Square Feet',\n",
    "                          'Full Baths',\n",
    "                          'Building Square Feet',\n",
    "                          'Rooms',\n",
    "                          'Fireplaces')\n",
    "    \n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['Sale Price'], axis = 1)\n",
    "    y = data.loc[:, 'Sale Price']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use `process_data_gm1` to clean our data, select features, and add our `TotalBathrooms` feature all in one step! This function also splits our data into `X`, a matrix of features, and `y`, a vector of sale prices. \n",
    "\n",
    "Run the cell below to feed our training and test data through the pipeline, generating `X_train`, `y_train`, `X_test`, and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process our training and test data in exactly the same way\n",
    "# Our functions make this very easy!\n",
    "X_train, y_train = process_data_gm(train)\n",
    "X_test, y_test = process_data_gm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Our First Model\n",
    "\n",
    "We are finally going to fit a model!  The model we will fit can be written as follows:\n",
    "\n",
    "$$\\text{SalePrice} = \\theta_0 + \\theta_1 \\cdot \\text{Gr_Liv_Area} + \\theta_2 \\cdot \\text{Garage_Area} + \\theta_3 \\cdot \\text{TotalBathrooms}$$\n",
    "\n",
    "In vector notation, the same equation would be written:\n",
    "\n",
    "$$y = \\vec\\theta \\cdot \\vec{x}$$\n",
    "\n",
    "where $y$ is the SalePrice, $\\vec\\theta$ is a vector of all fitted weights, and $\\vec{x}$ contains a 1 for the bias followed by each of the feature values.\n",
    "\n",
    "**Note:** Notice that all of our variables are continuous, except for `TotalBathrooms`, which takes on discrete ordered values (0, 0.5, 1, 1.5, ...). In this homework, we'll treat `TotalBathrooms` as a continuous quantitative variable in our model, but this might not be the best choice. The next homework may revisit the issue.\n",
    "\n",
    "## Question 7a <a name=\"q7a\"></a>\n",
    "\n",
    "We will use a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object as our linear model. In the cell below, create a `LinearRegression` object and name it `linear_model`.\n",
    "\n",
    "**Hint:** See the `fit_intercept` parameter and make sure it is set appropriately. The intercept of our model corresponds to $\\theta_0$ in the equation above.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression(fit_intercept=True) # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7b <a name=\"q7b\"></a>\n",
    "\n",
    "Now, remove the commenting and fill in the ellipses `...` below with `X_train`, `y_train`, `X_test`, or `y_test`.\n",
    "\n",
    "With the ellipses filled in correctly, the code below should fit our linear model to the training data and generate the predicted sale prices for both the training and test datasets.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1be99eea86f6cf57",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the lines below and fill in the ... with X_train, y_train, X_test, or y_test.\n",
    "# linear_model.fit(..., ...)\n",
    "# y_fitted = linear_model.predict(...)\n",
    "# y_predicted = linear_model.predict(...)\n",
    "# BEGIN SOLUTION NO PROMPT\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_fitted = linear_model.predict(X_train)\n",
    "y_predicted = linear_model.predict(X_test)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-930562b39ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q7b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ok' is not defined"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q7b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8a <a name=\"q8a\"></a>\n",
    "\n",
    "Is our linear model any good at predicting house prices? Let's measure the quality of our model by calculating the Root-Mean-Square Error (RMSE) between our predicted house prices and the true prices stored in `SalePrice`.\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price of house} - \\text{predicted price of house})^2}{\\text{# of houses in data set}}}$$\n",
    "\n",
    "In the cell below, write a function named `rmse` that calculates the RMSE of a model.\n",
    "\n",
    "**Hint:** Make sure you are taking advantage of vectorized code. This question can be answered without any `for` statements.\n",
    "\n",
    "*The provided tests check that you answered correctly, so that future analyses are not corrupted by a mistake.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      actual (1D array): vector of actual values\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2)) # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b802f4d9489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q8a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ok' is not defined"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q8a\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8b <a name=\"q8b\"></a>\n",
    "\n",
    "Now use your `rmse` function to calculate the training error and test error in the cell below.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to a non-negative number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260674.5844381157, 258144.35809396824)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_error = rmse(y_fitted, y_train) # SOLUTION\n",
    "test_error = rmse(y_predicted, y_test) # SOLUTION\n",
    "(training_error, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-4b663088fd52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q8b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ok' is not defined"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q8b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8c <a name=\"q8c\"></a>\n",
    "\n",
    "How much does including `TotalBathrooms` as a predictor reduce the RMSE of the model on the test set? That is, what's the difference between the RSME of a model that only includes `Gr_Liv_Area` and `Garage_Area` versus one that includes all three predictors?\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned the answer variable to a non-negative number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_difference = test_error_no_bath - test_error\n",
    "test_error_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q8c\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Residual Plots\n",
    "\n",
    "One way of understanding the performance (and appropriateness) of a model is through a residual plot. Run the cell below to plot the actual sale prices against the residuals of the model for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_predicted\n",
    "ax = sns.regplot(y_test, residuals)\n",
    "ax.set_xlabel('Sale Price (Test Data)')\n",
    "ax.set_ylabel('Residuals (Actual Price - Predicted Price)')\n",
    "ax.set_title(\"Residuals vs. Sale Price on Test Data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would see a horizontal line of points at 0 (perfect prediction!). The next best thing would be a homogenous set of points centered at 0. \n",
    "\n",
    "But alas, our simple model is probably too simple. The most expensive homes are systematically more expensive than our prediction. \n",
    "\n",
    "## Question 8d <a name=\"q8c\"></a>\n",
    "\n",
    "What changes could you make to your linear model to improve its accuracy and lower the test error? Suggest at least two things you could try in the cell below, and carefully explain how each change could potentially improve your model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 2 EXPORTED QUESTIONS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('hw5.ipynb', 'hw5.pdf')\n",
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 2 EXPORTED QUESTIONS -->\n",
    "\n",
    "# Save your notebook first, then run this cell to submit.\n",
    "import jassign.to_pdf\n",
    "jassign.to_pdf.generate_pdf('hw5.ipynb', 'hw5.pdf')\n",
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
